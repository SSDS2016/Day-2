{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# <center> Data Science Summer School - Split '16 </center>\n",
    "(c) 2016 Martin Tutek\n",
    "\n",
    "version: 0.1\n",
    "\n",
    "kernel: Python 2.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# <center>From tree to forest</center>\n",
    "\n",
    "<center>Or how I learned to stop worrying and love overfitting.</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Python imports & notebook setup\n",
    "# all plots will appear in the notebook\n",
    "%matplotlib inline \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import xgboost as xgb\n",
    "import seaborn as sns; sns.set() # make all the plots prettier\n",
    "from ipywidgets import interact, interactive, fixed # more plotting magic\n",
    "\n",
    "from matplotlib import style\n",
    "style.use('fivethirtyeight') # prettier-plots++\n",
    "\n",
    "# sklearn models & dataset wrangling\n",
    "from sklearn import tree \n",
    "from sklearn import ensemble \n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.datasets import make_moons # toy dataset generator\n",
    "from collections import Counter\n",
    "\n",
    "# make everything reproducible\n",
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "> *Random **what**? Why not use Deep Learning™*\n",
    "\n",
    "> _**What** boosting? I use AutoDifferentiation©, I don't need to know about gradients._\n",
    "\n",
    "**Actually**, there still exist cases where deep learning is *not* state of the art. Main things that those cases have in common are being **regression problems**, having a **low number of target classes**, largely **uncorrelated** features and/or having a **small number of training samples**.\n",
    "\n",
    "**Proof:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taken from [eXtreme Gradient Boosting repo](https://github.com/dmlc/xgboost/blob/master/demo/README.md)\n",
    "### Machine Learning Challenge Winning Solutions -- all in the last ~year\n",
    "\n",
    "XGBoost is extensively used by machine learning practitioners to create state of art data science solutions,\n",
    "this is a list of machine learning winning solutions with XGBoost.\n",
    "Please send pull requests if you find ones that are missing here.\n",
    "\n",
    "- Vlad Sandulescu, Mihai Chiru, 1st place of the [KDD Cup 2016 competition](https://kddcup2016.azurewebsites.net). Link to [the arxiv paper](http://arxiv.org/abs/1609.02728).\n",
    "- Marios Michailidis, Mathias Müller and HJ van Veen, 1st place of the [Dato Truely Native? competition](https://www.kaggle.com/c/dato-native). Link to [the Kaggle interview](http://blog.kaggle.com/2015/12/03/dato-winners-interview-1st-place-mad-professors/).\n",
    "- Vlad Mironov, Alexander Guschin, 1st place of the [CERN LHCb experiment Flavour of Physics competition](https://www.kaggle.com/c/flavours-of-physics). Link to [the Kaggle interview](http://blog.kaggle.com/2015/11/30/flavour-of-physics-technical-write-up-1st-place-go-polar-bears/).\n",
    "- Josef Slavicek, 3rd place of the [CERN LHCb experiment Flavour of Physics competition](https://www.kaggle.com/c/flavours-of-physics). Link to [the Kaggle interview](http://blog.kaggle.com/2015/11/23/flavour-of-physics-winners-interview-3rd-place-josef-slavicek/).\n",
    "- Mario Filho, Josef Feigl, Lucas, Gilberto, 1st place of the [Caterpillar Tube Pricing competition](https://www.kaggle.com/c/caterpillar-tube-pricing). Link to [the Kaggle interview](http://blog.kaggle.com/2015/09/22/caterpillar-winners-interview-1st-place-gilberto-josef-leustagos-mario/).\n",
    "- Qingchen Wang, 1st place of the [Liberty Mutual Property Inspection](https://www.kaggle.com/c/liberty-mutual-group-property-inspection-prediction). Link to [the Kaggle interview](http://blog.kaggle.com/2015/09/28/liberty-mutual-property-inspection-winners-interview-qingchen-wang/).\n",
    "- Chenglong Chen, 1st place of the [Crowdflower Search Results Relevance](https://www.kaggle.com/c/crowdflower-search-relevance). [Link to the winning solution](https://www.kaggle.com/c/crowdflower-search-relevance/forums/t/15186/1st-place-winner-solution-chenglong-chen/).\n",
    "- Alexandre Barachant (“Cat”) and Rafał Cycoń (“Dog”), 1st place of the [Grasp-and-Lift EEG Detection](https://www.kaggle.com/c/grasp-and-lift-eeg-detection). Link to [the Kaggle interview](http://blog.kaggle.com/2015/10/12/grasp-and-lift-eeg-winners-interview-1st-place-cat-dog/).\n",
    "- Halla Yang, 2nd place of the [Recruit Coupon Purchase Prediction Challenge](https://www.kaggle.com/c/coupon-purchase-prediction). Link to [the Kaggle interview](http://blog.kaggle.com/2015/10/21/recruit-coupon-purchase-winners-interview-2nd-place-halla-yang/).\n",
    "- Owen Zhang, 1st place of the [Avito Context Ad Clicks competition](https://www.kaggle.com/c/avito-context-ad-clicks). Link to [the Kaggle interview](http://blog.kaggle.com/2015/08/26/avito-winners-interview-1st-place-owen-zhang/).\n",
    "- Keiichi Kuroyanagi, 2nd place of the [Airbnb New User Bookings](https://www.kaggle.com/c/airbnb-recruiting-new-user-bookings). Link to [the Kaggle interview](http://blog.kaggle.com/2016/03/17/airbnb-new-user-bookings-winners-interview-2nd-place-keiichi-kuroyanagi-keiku/).\n",
    "- Marios Michailidis, Mathias Müller and Ning Situ, 1st place [Homesite Quote Conversion](https://www.kaggle.com/c/homesite-quote-conversion). Link to [the Kaggle interview](http://blog.kaggle.com/2016/04/08/homesite-quote-conversion-winners-write-up-1st-place-kazanova-faron-clobber/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A different point of view\n",
    "- Regression\n",
    "- Binary classification\n",
    "- Binary classification\n",
    "- Binary classification\n",
    "- Regression\n",
    "- Ranking (can be treated as regression)\n",
    "- Regression (ordinal low-dimensional classification)\n",
    "- Binary classification\n",
    "- Binary classification\n",
    "- Binary classification\n",
    "- Ranking (can be treated as regression)\n",
    "- Binary classification\n",
    "\n",
    "### So... how do they work?\n",
    "> *\"We are only as strong as we are united, as weak as we are divided.\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate a toy dataset similar to the one we used\n",
    "def noisy_sine(x):\n",
    "    return np.sin(x) + np.random.normal(scale=0.2, size=x.shape)\n",
    "\n",
    "x = np.linspace(0, 2*np.pi, num = 200)\n",
    "y = noisy_sine(x)\n",
    "\n",
    "x_test = np.linspace(2*np.pi, 2.5*np.pi, num=50)\n",
    "y_test = noisy_sine(x_test)\n",
    "\n",
    "plt.plot(x, np.sin(x), linewidth=3, c='g', alpha = 0.5, label = '$sin(x)$')\n",
    "plt.plot(x_test, np.sin(x_test), linewidth=3, c='g', alpha = 0.5)\n",
    "\n",
    "plt.scatter(x, noisy_sine(x), linewidth=1, label = '$Train$')\n",
    "plt.scatter(x_test, y_test, c='r', label = '$Test$')\n",
    "\n",
    "plt.legend(loc='upper center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This goes later\n",
    "\n",
    "x = x.reshape(x.shape[0], 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 1)\n",
    "\n",
    "# Decide which models we are going to use\n",
    "model_names = [\"Decision Tree\", \"Random Forests\", \"Gradient Boosting\"]\n",
    "\n",
    "regression_models = {\n",
    "    \"Decision Tree\" : tree.DecisionTreeRegressor, \n",
    "    \"Gradient Boosting\" : ensemble.GradientBoostingRegressor, \n",
    "    \"Random Forests\" : ensemble.RandomForestRegressor\n",
    "}\n",
    "\n",
    "model_params = {\n",
    "    \"Decision Tree\" : {\n",
    "        'max_depth' : 5\n",
    "    },\n",
    "    \"Gradient Boosting\" : {\n",
    "        'max_depth' : 5, 'n_estimators' : 10\n",
    "    },\n",
    "    \"Random Forests\" : {\n",
    "        'max_depth' : 5, 'n_estimators' : 10\n",
    "    }\n",
    "}\n",
    "\n",
    "# create a 1x3 grid of plots\n",
    "f, axarr = plt.subplots(3, 1, figsize=(6, 15))\n",
    "\n",
    "for idx, regression_model in enumerate(model_names):\n",
    "    # This is some dark magic you should remind me to explain if I forget\n",
    "    model = regression_models[regression_model](**model_params[regression_model])\n",
    "    model.fit(x, y)\n",
    "    \n",
    "    y_pred = model.predict(x_test)\n",
    "    y_train_pred = model.predict(x)\n",
    "    \n",
    "    train_error = metrics.mean_squared_error(y, y_train_pred)\n",
    "    test_error = metrics.mean_squared_error(y_test, y_pred)\n",
    "    print regression_model, 'Train MSE =', train_error, 'Test MSE', test_error \n",
    "    \n",
    "    # plot the test & train set\n",
    "    axarr[idx].scatter(x, y, c='b')\n",
    "    axarr[idx].scatter(x_test, y_test, c='r')\n",
    "    \n",
    "    axarr[idx].plot(x, y_train_pred, c=\"g\", linewidth = 2)\n",
    "    axarr[idx].plot(x_test, y_pred, c=\"g\", label=regression_model, linewidth = 2, alpha = 1)\n",
    "    axarr[idx].set_title(regression_model)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OK, so it's not that simple\n",
    "\n",
    "#### Q: What's wrong? (2 key points)\n",
    "- Not enough signal\n",
    "- What are the other model parameters?\n",
    "\n",
    "#### To the documentation!\n",
    "\n",
    "- [RandomForestRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)\n",
    "\n",
    "- [RandomForestClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "\n",
    "    - **n_estimators=10:** The number of trees used in the ensemble\n",
    "    - **criterion='gini':** Do we **really** care? (useful to change around)\n",
    "    - **max_features :** Max number of features to consider in each split - default = $\\sqrt{n}$, where $n$ is the number of features (default is pretty good)\n",
    "    - **max_depth :** Maximum depth of each tree in the ensemble (useful to change around)\n",
    "    - **min_samples_split :** Not the minimum number of samples in Split - this is the minimum number of samples required in a node to continue splitting. Default = 2 (default is pretty good)\n",
    "    - **class_weight :** Balancing the datasets - dict, list of dicts, “balanced”, “balanced_subsample” - worth considering if you have highly imbalanced classes. *(Just for classification)*\n",
    "\n",
    "- [GradientBoostingRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html) \n",
    "\n",
    "- [GradientBoostingClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html) \n",
    "\n",
    "    - More or less the same tricks as Random Forests, except...\n",
    "    - **learning_rate :** This is NOT the step we take according to the gradient of the error function, like in gradient descent. This is the contribution for each $tree \\in n_{estimators}$ in the total ensemble! There is a trade-off between the learning rate and the number of estimators - as we decrease the learning rate, our generalization becomes better, however we need a larger amount of trees, which slows down the training.\n",
    "    - **subsample :** The fraction of samples to be used for fitting the individual base learners. Choosing subsample < 1.0 (bagging) leads to a reduction of variance and an increase in bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Or, even better, to the [ensemble methods page](http://scikit-learn.org/stable/modules/ensemble.html):\n",
    "### Bagging vs Boosting\n",
    "#### Bagging methods\n",
    "In bagging, we choose random subsets of the dataset (samples!), train several 'weak' (simple) learners and aggregate (average) their results. The simple learners are trained independently of each other and the process can herefore be easily parallelized. It is recommended to use subsets of features as well as samples as it leads to better generalization. \n",
    "\n",
    "**Q:** Can you think of any exception to the last sentence?\n",
    "<img style=\"float: center;\" src=\"img/bagging.png\", width=\"70%\" height=\"70%\">\n",
    "\n",
    "#### Boosting methods\n",
    "In boosting, the weak learners are trained sequentially with a goal to reduce the error of the previous learner(s) by adding weight to previously misclassified samples. This leads to each following learner correcting the mistakes of the previous one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study - [Kaggle bike sharing demand](https://www.kaggle.com/c/bike-sharing-demand)\n",
    "\n",
    "### Forecast use of a city bikeshare system\n",
    "\n",
    "#### Data Fields\n",
    "- datetime - hourly date + timestamp  \n",
    "- season -  1 = spring, 2 = summer, 3 = fall, 4 = winter \n",
    "- holiday - whether the day is considered a holiday\n",
    "- workingday - whether the day is neither a weekend nor holiday\n",
    "- weather \n",
    "  - 1: Clear, Few clouds, Partly cloudy, Partly cloudy \n",
    "  - 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist \n",
    "  - 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds \n",
    "  - 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog \n",
    "- temp - temperature in Celsius\n",
    "- atemp - \"feels like\" temperature in Celsius\n",
    "- humidity - relative humidity\n",
    "- windspeed - wind speed\n",
    "- casual - number of non-registered user rentals initiated\n",
    "- registered - number of registered user rentals initiated\n",
    "- count - number of total rentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the data and print out the basics\n",
    "train_source = 'dataset/bikes.csv'\n",
    "bikes = pd.read_csv(train_source)\n",
    "print bikes.shape\n",
    "print bikes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "original_features = bikes.columns.values[1:-3] \n",
    "# 'casual' and 'registered' sum up to 'count', and complicate things too much for now\n",
    "target = bikes.columns.values[-1] \n",
    "print original_features, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt = pd.DatetimeIndex(bikes['datetime']) # parse datetime into python's datetime object\n",
    "bikes.set_index(dt, inplace=True)\n",
    "\n",
    "# This allows us to add some features \n",
    "bikes['day'] = dt.day\n",
    "bikes['month'] = dt.month\n",
    "bikes['year'] = dt.year\n",
    "bikes['hour'] = dt.hour\n",
    "bikes['dow'] = dt.dayofweek\n",
    "bikes['woy'] = dt.weekofyear\n",
    "\n",
    "features = np.concatenate((original_features, bikes.columns.values[12:]))\n",
    "print features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Always plot the data\n",
    "\n",
    "Pandas resample is relatively weakly documented - however is really useful when working with time-series or sequential data: [Stackoverflow post](http://stackoverflow.com/questions/17001389/pandas-resample-documentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "monthly_plot = bikes.resample('M').sum().plot(title=\"Rentals by month\", y = \"count\", linewidth=1, legend=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "by_hour = bikes.groupby('hour')[['count']].agg(sum)\n",
    "plt.plot(by_hour, linewidth=1)\n",
    "plt.title(\"Rentals by hour in day\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_rmsle(y_pred, y_actual):\n",
    "    # Root mean square logarithmic arror - due to the sums otherwise being too large\n",
    "    diff = np.log(y_pred + 1) - np.log(y_actual + 1)\n",
    "    mean_error = np.square(diff).mean()\n",
    "    return np.sqrt(mean_error)\n",
    "\n",
    "def train_test_split_day(data, cutoff_day=15):\n",
    "    train = data[data['day'] <= cutoff_day]\n",
    "    test = data[data['day'] > cutoff_day]\n",
    "\n",
    "    return train, test\n",
    "\n",
    "def train_test_split_last_n(data, cutoff=1000):\n",
    "    train = data[:-cutoff]\n",
    "    test = data[-cutoff:]\n",
    "    \n",
    "    return train, test    \n",
    "\n",
    "def kfold(model, bikes, features, target = 'count', k = 5):\n",
    "    # kfold cross-validation\n",
    "    skf = KFold(len(bikes), k, shuffle=True)\n",
    "    \n",
    "    rmslerrs = []\n",
    "    \n",
    "    for train, test in skf:\n",
    "        bikes_train, bikes_test = bikes.iloc[train], bikes.iloc[test]\n",
    "        model.fit(bikes_train[features], bikes_train[target])\n",
    "        predictions = model.predict(bikes_test[features])\n",
    "\n",
    "        RMSLE = get_rmsle(predictions, bikes_test[target])\n",
    "        rmslerrs.append(RMSLE)\n",
    "    \n",
    "    print \"The Average RMSLE = {}, stdev = {}\".format(np.mean(rmslerrs), np.std(rmslerrs))\n",
    "    \n",
    "\n",
    "def dataset_performance(model, bikes_train, bikes_test, features, target = 'count', mode = 'lastn'):\n",
    "    modes = ['lastn', 'day']\n",
    "    \n",
    "    model.fit(bikes_train[features], bikes_train[target])\n",
    "    predictions = model.predict(bikes_test[features])\n",
    "    \n",
    "    RMSLE = get_rmsle(predictions, bikes_test[target])\n",
    "    print \"The Root mean squared log error is {}\".format(RMSLE)\n",
    "    \n",
    "    # plotting \n",
    "    if mode == 'lastn':\n",
    "        # Assuming datetime index, otherwise will break\n",
    "        bikes_test['count_pred'] = predictions\n",
    "        grouped_by_day = bikes_test.resample('D').sum() \n",
    "        indices = range(len(grouped_by_day.index))\n",
    "        plt.plot(grouped_by_day.index, grouped_by_day['count'], c='g', label='Actual values', linewidth=2, alpha=0.5)\n",
    "        plt.plot(grouped_by_day.index, grouped_by_day['count_pred'], c='b', label='Predicted values', linewidth=1)\n",
    "        bikes_test.drop(['count_pred'], axis=1, inplace=True)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    elif mode == 'day':\n",
    "        bikes_test['count_pred'] = predictions\n",
    "        grouped_by_day = bikes_test.resample('D').sum() \n",
    "        indices = range(len(grouped_by_day.index))\n",
    "        plt.scatter(grouped_by_day.index, grouped_by_day['count'], c='g', label='Actual values', linewidth=2, alpha=0.5)\n",
    "        plt.scatter(grouped_by_day.index, grouped_by_day['count_pred'], c='b', label='Predicted values', linewidth=1)\n",
    "        bikes_test.drop(['count_pred'], axis=1, inplace=True)\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print \"Skipping plotting, unknown mode: {}, supported modes for plot: {}.\".format(mode, ', '.join(modes))\n",
    "    \n",
    "    return RMSLE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Feature correlation matrix\n",
    "bikes[features].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Do we want to keep all of the features? Do we want to add some?\n",
    "print features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_names = [\"Decision Tree\", \"Random Forests\", \"Gradient Boosting\"]\n",
    "\n",
    "regression_models = {\n",
    "    \"Decision Tree\" : tree.DecisionTreeRegressor, \n",
    "    \"Gradient Boosting\" : ensemble.GradientBoostingRegressor, \n",
    "    \"Random Forests\" : ensemble.RandomForestRegressor\n",
    "}\n",
    "\n",
    "model_params = {\n",
    "    \"Decision Tree\" : {\n",
    "        'max_depth' : 5\n",
    "    },\n",
    "    \"Gradient Boosting\" : {\n",
    "        'max_depth' : 5, 'n_estimators' : 10\n",
    "    },\n",
    "    \"Random Forests\" : {\n",
    "        'max_depth' : 5, 'n_estimators' : 10\n",
    "    }\n",
    "}\n",
    "\n",
    "modes = {\n",
    "    'lastn' : train_test_split_last_n, \n",
    "    'day' : train_test_split_day\n",
    "}\n",
    "\n",
    "mode = 'lastn'\n",
    "\n",
    "cross_validate_best = True # set to false if you don't want to run cross-validation\n",
    "\n",
    "# Split data into train / 'test'\n",
    "data_train, data_test = modes[mode](bikes) # Option: last n, or last x days in month\n",
    "\n",
    "# Evaluate all models (Option: evaluate just one for speed)\n",
    "model_scores = {}\n",
    "for model_name in model_names:\n",
    "    params = model_params[model_name]\n",
    "    print \"Running {}, params = {}\".format(model_name, str(params))\n",
    "    model = regression_models[model_name](**params)\n",
    "    \n",
    "    err = dataset_performance(model, data_train, data_test, features, mode=mode)\n",
    "    model_scores[model_name] = err\n",
    "    \n",
    "# Cross-validate best model?\n",
    "if cross_validate_best:\n",
    "    sorted_scores = sorted(model_scores.items(), key=lambda t:t[1])\n",
    "    best_model = sorted_scores[0][0]\n",
    "\n",
    "    print \"Running k-fold cross validation on best model: {}\".format(best_model)\n",
    "    m = regression_models[best_model](**model_params[best_model])\n",
    "    kfold(m, bikes, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So, what did the winning model use? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is it all really that good?\n",
    "\n",
    "**A:** Yes and ... no. Gradient boosted models are really good at winning online competitions - often due to overfitting the test data (yes, this is possible), however they are not as useful in real life. \n",
    "\n",
    "If you check the open-sourced top solutions for some of the competitions, many of them rely heavily on **feature engineering** (which is good), but sometimes also produces unintuitive features which perform well on that train/test split. Another disadvantage is that running **massive ensembles** of cascaded models and various ensembling techniques almost always proves to be better - however those models lose any resemblance of interpretability.\n",
    "\n",
    "A really important part of running gradient boosted models is preventing overfitting - which proves to be really hard ($1e-5$ differences in learning rate can be crucial), and the top libraries for gradient boosting (XGBoost, etc) rely heavily on various regularization techniques (heuristics, early stopping) and optimizations in runtime (to allow larger models)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra: Useful tricks with forests\n",
    "#### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "forest = ensemble.RandomForestRegressor(max_depth = 8, n_estimators = 100)\n",
    "forest.fit(bikes[features], bikes[target])\n",
    "\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree_.feature_importances_ for tree_ in forest.estimators_], axis=0)\n",
    "print \"Features: \", ', '.join(features)\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "feature_names = features[indices]\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(bikes[features].shape[1]):\n",
    "    print(\"Feature #%d: %s importance: %f\" % (f+1, feature_names[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(bikes[features].shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(bikes[features].shape[1]), range(1, bikes[features].shape[1] + 1))\n",
    "plt.xlim([-1, bikes[features].shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can actually get the trees from the forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbm = ensemble.GradientBoostingRegressor(learning_rate=0.01, max_depth = 8, n_estimators = 300)\n",
    "gbm.fit(bikes[features], bikes[target])\n",
    "\n",
    "top_n = 5\n",
    "\n",
    "for idx, estimator in enumerate(gbm.estimators_[:top_n]):\n",
    "    print estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
